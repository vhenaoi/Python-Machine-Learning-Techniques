{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1NjvU7aVTo2AavhhhoV3C1bh1jn-tPOuQ","authorship_tag":"ABX9TyOW5mxRWH6D3CrqY4z7AeTS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Data**"],"metadata":{"id":"LuIx8otYuWP5"}},{"cell_type":"code","execution_count":63,"metadata":{"id":"5J4vwyWDZAZ-","executionInfo":{"status":"ok","timestamp":1724543717800,"user_tz":300,"elapsed":220,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}}},"outputs":[],"source":["# Import the pandas library for data manipulation and analysis\n","import pandas as pd\n","\n","# Import numpy for numerical operations and handling arrays\n","import numpy as np\n","\n","# Import LogisticRegression from sklearn for logistic regression model\n","from sklearn.linear_model import LogisticRegression\n","\n","# Import matplotlib for creating visualizations and plots\n","import matplotlib.pyplot as plt\n","\n","# Import seaborn for advanced statistical data visualization\n","import seaborn as sns\n","\n","# Import StandardScaler from sklearn for standardizing features\n","from sklearn.preprocessing import StandardScaler\n","\n","# Import statsmodels for statistical models and tests\n","import statsmodels.api as sm\n","from statsmodels.formula.api import ols  # Import OLS (Ordinary Least Squares) for linear regression models\n","\n","# Import kstest and norm from scipy for statistical tests and normal distribution\n","from scipy.stats import kstest, norm\n","\n","# Import pairwise_tukeyhsd from statsmodels for Tukey's HSD test for multiple comparisons\n","from statsmodels.stats.multicomp import pairwise_tukeyhsd\n","\n","# Import SelectKBest and f_classif from sklearn for feature selection\n","from sklearn.feature_selection import SelectKBest, f_classif\n","\n","# Import MinMaxScaler from sklearn for scaling features to a given range\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Import train_test_split from sklearn for splitting data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","# Import various metrics from sklearn for evaluating models\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","# Import LinearDiscriminantAnalysis for linear dimensionality reduction and classification\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","\n","# Import additional regression models from sklearn\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n","\n","# Import support vector machine classifiers and regressors from sklearn\n","from sklearn.svm import SVC, SVR\n","\n","# Import k-nearest neighbors classifier from sklearn\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Import regression metrics from sklearn for evaluating model performance\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","# Import load_workbook and Workbook from openpyxl for handling Excel files\n","from openpyxl import load_workbook, Workbook\n","\n","# Import os for interacting with the operating system (e.g., file paths)\n","import os\n","\n","# Import GridSearchCV and RandomizedSearchCV for hyperparameter tuning\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","\n","# Import additional metrics from sklearn for model evaluation\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n","\n","# Import joblib for saving and loading models\n","import joblib\n","\n","# Import learning_curve from sklearn for plotting learning curves\n","from sklearn.model_selection import learning_curve\n","\n","# Import cross_val_score from sklearn for cross-validation\n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"markdown","source":["*Summary*:\n","\n","* **Paths Definition**: Sets file paths for data.\n","* **Data Loading**: Reads Excel files into DataFrames.\n","* **Column Renaming**: Standardizes column names.\n","* **Data Type Conversion**: Ensures consistent data types for merging.\n","* **Data Merging**: Combines DataFrames on common columns.\n","* **Verification**: Prints DataFrame column names and sizes, and shows the first rows of the merged DataFrame."],"metadata":{"id":"u2rndxrnECLc"}},{"cell_type":"code","source":["# Specify the path where the file of interest is located\n","# The file paths are set as raw strings to handle any special characters or escape sequences\n","path_TELE = rf'/content/drive/MyDrive/Sapienza/Resources/WP2 -TELEMAIA Associazione tra EEG e TELEMONITORING features in Nold e MCI.xlsx'\n","path_EEG = rf'/content/drive/MyDrive/Sapienza/Resources/WP2 -TELEMAIA EEG features in Nold e PD con deficit cognitivi.xlsx'\n","path_MRI = rf'/content/drive/MyDrive/Sapienza/Resources/WP2 -TELEMAIA MRI features in Nold e PD con deficit cognitivi.xlsx'\n","\n","# Create a variable with the Excel information in a data frame structure\n","# Load data from specified Excel sheets into pandas DataFrames\n","data_tele = pd.read_excel(path_TELE, sheet_name='best')\n","data_eeg = pd.read_excel(path_EEG, sheet_name='all')\n","data_mri = pd.read_excel(path_MRI, sheet_name='all')\n","\n","# Rename columns in the data_tele DataFrame for consistency\n","# Rename 'Codice TELEMAIA new' to 'Subj' and 'Group TELEMAIA' to 'Group'\n","data_tele.rename(columns={'Codice TELEMAIA new': 'Subj'}, inplace=True)\n","data_tele.rename(columns={'Group TELEMAIA': 'Group'}, inplace=True)\n","\n","# Rename column in the data_eeg DataFrame\n","# Rename 'MMSEg' to 'MMSE' to match the column name in data_tele\n","data_eeg.rename(columns={'MMSEg': 'MMSE'}, inplace=True)\n","\n","# Convert the 'Unit' column in each DataFrame to string type\n","# This ensures consistent data types for merging\n","data_tele['Unit'] = data_tele['Unit'].astype(str)\n","data_eeg['Unit'] = data_eeg['Unit'].astype(str)\n","\n","# Set 'Unit' column in data_mri to a constant value 'MRI'\n","# Ensure that the column type is string for consistency\n","data_mri['Unit'] = 'MRI'  # Ensure size compatibility with the DataFrame\n","data_mri['Unit'] = data_mri['Unit'].astype(str)\n","\n","# Print column names and sizes of DataFrames to verify correct loading and renaming\n","print(f\"Column names in data_tele: {data_tele.columns}, Size: {data_tele.shape}\")\n","print(f\"\\nColumn names in data_eeg:{data_eeg.columns}, Size: {data_eeg.shape}\")\n","print(f\"\\nColumn names in data_mri:{data_mri.columns}, Size: {data_mri.shape}\")\n","\n","# Perform an outer merge of the three DataFrames on specified columns\n","# This combines the data based on matching values in the specified columns\n","df = (data_tele.merge(data_eeg, on=['Subj', 'Group', 'Age', 'Sex', 'Education', 'MMSE', 'Unit'], how='outer')\n","         .merge(data_mri, on=['Subj', 'Group', 'Age', 'Sex', 'Education', 'MMSE', 'Unit'], how='outer'))\n","\n","# Display the first few rows of the merged DataFrame to verify the result\n","print(\"Merged Data:\")\n","print(df)"],"metadata":{"id":"YxZcpNHIxf2I","executionInfo":{"status":"ok","timestamp":1724543718610,"user_tz":300,"elapsed":533,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5b7c44d-5562-410f-c3de-922153f047b2"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Column names in data_tele: Index(['Subj', 'Group', 'Unit', 'Age', 'Sex', 'Education', 'MMSE', 'TASK1',\n","       'TASK2', 'TASK3', 'TASK4', 'TASK5', 'TASK6', 'TASK7', 'theta_P'],\n","      dtype='object'), Size: (47, 15)\n","\n","Column names in data_eeg:Index(['Subj', 'Group', 'Unit', 'Age', 'Sex', 'Education', 'MMSE', 'MMSEcorr',\n","       'TF', 'IAF', 'UPDRS III', 'De-F', 'De-C', 'De-P', 'De-O', 'De-T',\n","       'De-L', 'Th-F', 'Th-C', 'Th-P', 'Th-O', 'Th-T', 'Th-L', 'A1-F', 'A1-C',\n","       'A1-P', 'A1-O', 'A1-T', 'A1-L', 'A2-F', 'A2-C', 'A2-P', 'A2-O', 'A2-T',\n","       'A2-L', 'A3-F', 'A3-C', 'A3-P', 'A3-O', 'A3-T', 'A3-L', 'B1-F', 'B1-C',\n","       'B1-P', 'B1-O', 'B1-T', 'B1-L', 'B2-F', 'B2-C', 'B2-P', 'B2-O', 'B2-T',\n","       'B2-L', 'Ga-F', 'Ga-C', 'Ga-P', 'Ga-O', 'Ga-T', 'Ga-L', 'De-global',\n","       'Th-global', 'A1-global', 'A3-global'],\n","      dtype='object'), Size: (104, 63)\n","\n","Column names in data_mri:Index(['Subj', 'Group', 'Age', 'Sex', 'Education', 'MMSE',\n","       'Visual_Network_Normalized', 'SomatoMotor_Network_Normalized',\n","       'DAN_Normalized', 'VAN_Normalized', 'Limbic_Network_Normalized',\n","       'FrontoParietal_Network_Normalized', 'DMN_Normalized', 'Unit'],\n","      dtype='object'), Size: (75, 14)\n","Merged Data:\n","                 Subj Group         Unit   Age  Sex  Education  MMSE  TASK1  \\\n","0    Telemaia_MCI_001   MCI  SANT ANDREA  80.0    1          5    28   35.0   \n","1    Telemaia_MCI_002   MCI  SANT ANDREA  78.0    0          8    19   30.0   \n","2    Telemaia_MCI_003   MCI  SANT ANDREA  81.0    1          5    26   35.0   \n","3    Telemaia_MCI_004   MCI  SANT ANDREA  70.0    1          5    22   80.0   \n","4    Telemaia_MCI_005   MCI  SANT ANDREA  84.0    1         13    25   50.0   \n","..                ...   ...          ...   ...  ...        ...   ...    ...   \n","221         sub-psin1    HC          MRI  59.0    0          5    24    NaN   \n","222        sub-pspam1    HC          MRI  57.0    0          5    26    NaN   \n","223        sub-pssog1    HC          MRI  66.0    1         11    27    NaN   \n","224        sub-psyil1    HC          MRI  52.0    0         13    28    NaN   \n","225        sub-pukab1    HC          MRI  58.0    0          5    29    NaN   \n","\n","     TASK2  TASK3  ...  Th-global  A1-global  A3-global  \\\n","0     75.0   80.0  ...        NaN        NaN        NaN   \n","1     90.0   90.0  ...        NaN        NaN        NaN   \n","2     75.0   70.0  ...        NaN        NaN        NaN   \n","3     65.0   80.0  ...        NaN        NaN        NaN   \n","4     10.0   70.0  ...        NaN        NaN        NaN   \n","..     ...    ...  ...        ...        ...        ...   \n","221    NaN    NaN  ...        NaN        NaN        NaN   \n","222    NaN    NaN  ...        NaN        NaN        NaN   \n","223    NaN    NaN  ...        NaN        NaN        NaN   \n","224    NaN    NaN  ...        NaN        NaN        NaN   \n","225    NaN    NaN  ...        NaN        NaN        NaN   \n","\n","     Visual_Network_Normalized  SomatoMotor_Network_Normalized  \\\n","0                          NaN                             NaN   \n","1                          NaN                             NaN   \n","2                          NaN                             NaN   \n","3                          NaN                             NaN   \n","4                          NaN                             NaN   \n","..                         ...                             ...   \n","221                   0.045691                        0.041898   \n","222                   0.048075                        0.040941   \n","223                   0.046484                        0.042698   \n","224                   0.061751                        0.058162   \n","225                   0.058792                        0.054753   \n","\n","     DAN_Normalized  VAN_Normalized  Limbic_Network_Normalized  \\\n","0               NaN             NaN                        NaN   \n","1               NaN             NaN                        NaN   \n","2               NaN             NaN                        NaN   \n","3               NaN             NaN                        NaN   \n","4               NaN             NaN                        NaN   \n","..              ...             ...                        ...   \n","221        0.032159        0.029492                   0.034101   \n","222        0.031490        0.031206                   0.033951   \n","223        0.032838        0.031772                   0.036331   \n","224        0.042332        0.040684                   0.042089   \n","225        0.034751        0.039424                   0.042248   \n","\n","     FrontoParietal_Network_Normalized  DMN_Normalized  \n","0                                  NaN             NaN  \n","1                                  NaN             NaN  \n","2                                  NaN             NaN  \n","3                                  NaN             NaN  \n","4                                  NaN             NaN  \n","..                                 ...             ...  \n","221                           0.040179        0.072249  \n","222                           0.041494        0.074479  \n","223                           0.039410        0.072255  \n","224                           0.051440        0.098638  \n","225                           0.049789        0.087667  \n","\n","[226 rows x 78 columns]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-64-e5c7ad5e4abe>:39: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n","  df = (data_tele.merge(data_eeg, on=['Subj', 'Group', 'Age', 'Sex', 'Education', 'MMSE', 'Unit'], how='outer')\n","<ipython-input-64-e5c7ad5e4abe>:39: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n","  df = (data_tele.merge(data_eeg, on=['Subj', 'Group', 'Age', 'Sex', 'Education', 'MMSE', 'Unit'], how='outer')\n"]}]},{"cell_type":"code","source":["# Display the column names of the merged DataFrame\n","print(df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRzx9xfp0T3n","executionInfo":{"status":"ok","timestamp":1724543718611,"user_tz":300,"elapsed":9,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}},"outputId":"40c00f7a-93a4-42d4-de44-920490398f56"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Subj', 'Group', 'Unit', 'Age', 'Sex', 'Education', 'MMSE', 'TASK1',\n","       'TASK2', 'TASK3', 'TASK4', 'TASK5', 'TASK6', 'TASK7', 'theta_P',\n","       'MMSEcorr', 'TF', 'IAF', 'UPDRS III', 'De-F', 'De-C', 'De-P', 'De-O',\n","       'De-T', 'De-L', 'Th-F', 'Th-C', 'Th-P', 'Th-O', 'Th-T', 'Th-L', 'A1-F',\n","       'A1-C', 'A1-P', 'A1-O', 'A1-T', 'A1-L', 'A2-F', 'A2-C', 'A2-P', 'A2-O',\n","       'A2-T', 'A2-L', 'A3-F', 'A3-C', 'A3-P', 'A3-O', 'A3-T', 'A3-L', 'B1-F',\n","       'B1-C', 'B1-P', 'B1-O', 'B1-T', 'B1-L', 'B2-F', 'B2-C', 'B2-P', 'B2-O',\n","       'B2-T', 'B2-L', 'Ga-F', 'Ga-C', 'Ga-P', 'Ga-O', 'Ga-T', 'Ga-L',\n","       'De-global', 'Th-global', 'A1-global', 'A3-global',\n","       'Visual_Network_Normalized', 'SomatoMotor_Network_Normalized',\n","       'DAN_Normalized', 'VAN_Normalized', 'Limbic_Network_Normalized',\n","       'FrontoParietal_Network_Normalized', 'DMN_Normalized'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["# Create a MinMaxScaler object to scale features between 0 and 1\n","scaler = MinMaxScaler()\n","\n","# Specify the columns that need to be scaled\n","columns_to_scale = ['Age', 'Education']\n","\n","# Fit the scaler on the specified columns and transform them\n","df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n","\n","# Print the first few rows of the scaled columns to verify the scaling\n","print(df[columns_to_scale].head())\n","\n","# Define a list of EEG feature names\n","EEG = [ 'De-F', 'De-C', 'De-P', 'De-O',\n","        'De-T', 'De-L', 'Th-F', 'Th-C', 'Th-P', 'Th-O', 'Th-T', 'Th-L', 'A1-F',\n","        'A1-C', 'A1-P', 'A1-O', 'A1-T', 'A1-L', 'A2-F', 'A2-C', 'A2-P', 'A2-O',\n","        'A2-T', 'A2-L', 'A3-F', 'A3-C', 'A3-P', 'A3-O', 'A3-T', 'A3-L', 'B1-F',\n","        'B1-C', 'B1-P', 'B1-O', 'B1-T', 'B1-L', 'B2-F', 'B2-C', 'B2-P', 'B2-O',\n","        'B2-T', 'B2-L', 'Ga-F', 'Ga-C', 'Ga-P', 'Ga-O', 'Ga-T', 'Ga-L',\n","        'De-global', 'Th-global', 'A1-global', 'A3-global']\n","\n","# Replace hyphens with underscores in column names if they are in the EEG list\n","df.columns = [col.replace('-', '_') if col in EEG else col for col in df.columns]\n","\n","# Define lists of column names for different categories\n","DEPENDENTS = ['Group', 'MMSE']\n","DEMOGRAPHICS = ['Age', 'Sex', 'Education']\n","EEG = ['De_F', 'De_C', 'De_P', 'De_O',\n","       'De_T', 'De_L', 'Th_F', 'Th_C', 'Th_P', 'Th_O', 'Th_T', 'Th_L', 'A1_F',\n","       'A1_C', 'A1_P', 'A1_O', 'A1_T', 'A1_L', 'A2_F', 'A2_C', 'A2_P', 'A2_O',\n","       'A2_T', 'A2_L', 'A3_F', 'A3_C', 'A3_P', 'A3_O', 'A3_T', 'A3_L', 'B1_F',\n","       'B1_C', 'B1_P', 'B1_O', 'B1_T', 'B1_L', 'B2_F', 'B2_C', 'B2_P', 'B2_O',\n","       'B2_T', 'B2_L', 'Ga_F', 'Ga_C', 'Ga_P', 'Ga_O', 'Ga_T', 'Ga_L',\n","       'De_global', 'Th_global', 'A1_global', 'A3_global']\n","MRI = ['Visual_Network_Normalized', 'SomatoMotor_Network_Normalized',\n","       'DAN_Normalized', 'VAN_Normalized', 'Limbic_Network_Normalized',\n","       'FrontoParietal_Network_Normalized', 'DMN_Normalized']\n","TASK = ['TASK1', 'TASK2', 'TASK3', 'TASK4', 'TASK5', 'TASK6', 'TASK7']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OlepN0Pg0YdK","executionInfo":{"status":"ok","timestamp":1724543718611,"user_tz":300,"elapsed":6,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}},"outputId":"4f309c3d-dd1b-45d4-d281-e28770ce10b9"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["        Age  Education\n","0  0.888889   0.238095\n","1  0.857143   0.380952\n","2  0.904762   0.238095\n","3  0.730159   0.238095\n","4  0.952381   0.619048\n"]}]},{"cell_type":"code","source":["# Define the dependent variables for classification and regression\n","\n","# Create a mapping dictionary to convert 'Group' values into numerical classes\n","group_mapping = {'HC': 0, 'PDD': 1, 'MCI': 1, 'PD': 1}\n","\n","# Map the values in the 'Group' column using the created dictionary to get classification labels\n","y_class = df[DEPENDENTS[0]].map(group_mapping)\n","\n","# Extract the dependent variable for regression from the DataFrame\n","y_reg = df[DEPENDENTS[1]]\n","\n","# Extract the dependent variable for another regression task (TASK columns)\n","y_reg_2 = df[TASK]\n","\n","# Define the independent variables for different models\n","\n","# Independent variables for classification using EEG features\n","X_class_EEG = df[DEMOGRAPHICS + EEG]\n","\n","# Independent variables for classification using MRI features\n","X_class_MRI = df[DEMOGRAPHICS + MRI]\n","\n","# Independent variables for classification using both EEG and MRI features\n","X_class_EEG_MRI = df[DEMOGRAPHICS + EEG + MRI]\n","\n","# Independent variables for regression using EEG features\n","X_reg_EEG = df[DEMOGRAPHICS + EEG]\n","\n","# Independent variables for regression using MRI features\n","X_reg_MRI = df[DEMOGRAPHICS + MRI]\n","\n","# Independent variables for regression using both EEG features and TASK variables\n","X_reg_TELE_EEG = df[DEMOGRAPHICS + EEG + TASK]\n","\n","# Independent variables for regression using both MRI features and TASK variables\n","X_reg_TELE_MRI = df[DEMOGRAPHICS + MRI + TASK]\n","\n","# Independent variables for regression using only TASK variables\n","X_reg_TELE = df[DEMOGRAPHICS + TASK]"],"metadata":{"id":"oPJAKSYO0cx8","executionInfo":{"status":"ok","timestamp":1724543718611,"user_tz":300,"elapsed":4,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}}},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"KdUWTTWoKY4t"}},{"cell_type":"code","source":["def select_features(X, y):\n","    # Remove rows with NaN values from X and filter y to match X's index\n","    X = X.dropna()\n","    y = y[X.index]\n","\n","    # List of all metrics (features) to be compared\n","    metrics = X.columns\n","\n","    # Dictionary to store results for each metric\n","    results = {}\n","\n","    for metric in metrics:\n","        try:\n","            # Perform ANOVA to check if there are statistically significant differences\n","            formula = f'{metric} ~ C(Group)'\n","            model = ols(formula, data=df).fit()  # Fit an OLS model\n","            anova_table = sm.stats.anova_lm(model, typ=2)  # Compute ANOVA table\n","\n","            # Perform normality test (Kolmogorov-Smirnov test)\n","            stat, p_value = kstest(df[metric], norm.cdf)  # Test for normality\n","\n","            # Store results in the dictionary\n","            results[metric] = {\n","                'anova': anova_table,\n","                'normality_p_value': p_value\n","            }\n","\n","            # Apply logarithmic transformation if normality p-value is significant\n","            if p_value < 0.05:\n","                df[f'log_{metric}'] = np.log(df[metric] + 1)  # Add 1 to avoid log(0)\n","                # Optional: Uncomment to debug log transformation\n","                # print(f'Applied logarithmic transformation to {metric}')\n","\n","        except Exception as e:\n","            # Handle exceptions and print errors for debugging\n","            print(f'Error processing metric {metric}: {e}')\n","\n","    # Perform Tukey's post-hoc test to find specific group differences\n","    for metric in metrics:\n","        if metric in df.columns:\n","            tukey = pairwise_tukeyhsd(df[metric], df['Group'])\n","            # Optional: Uncomment to debug Tukey's HSD results\n","            # print(f'Tukey HSD test results for {metric}:')\n","            # print(tukey)\n","\n","    # Feature selection using ANOVA F-value\n","    k = X.shape[1]  # Number of features to select (all features in this case)\n","    anova_selector = SelectKBest(score_func=f_classif, k=k)\n","    X_selected = anova_selector.fit_transform(X, y)  # Fit and transform the data\n","\n","    # Get the indices of the selected features\n","    selected_features = anova_selector.get_support(indices=True)\n","    # Print the names of selected features\n","    print(\"Selected features:\", [X.columns[i] for i in selected_features])\n","\n","    return X_selected, y"],"metadata":{"id":"gF5txU1e0g4p","executionInfo":{"status":"ok","timestamp":1724543718611,"user_tz":300,"elapsed":3,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["def save_excel(results_df, path, sheet_name):\n","    \"\"\"\n","    Save a DataFrame to an Excel file. If the file already exists, the function appends the DataFrame\n","    to the existing file, replacing the specified sheet if it exists.\n","\n","    Parameters:\n","    - results_df (pd.DataFrame): The DataFrame to be saved.\n","    - path (str): The path to the Excel file.\n","    - sheet_name (str): The name of the sheet where the DataFrame will be saved.\n","    \"\"\"\n","    # Round the DataFrame values to 2 decimal places for better readability\n","    results_df = results_df.round(2)\n","\n","    # Check if the file already exists\n","    if os.path.exists(path):\n","        # Open the existing Excel file and append the DataFrame\n","        with pd.ExcelWriter(path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n","            # Save the DataFrame to the specified sheet, replacing it if it already exists\n","            results_df.to_excel(writer, sheet_name=sheet_name, index=True)\n","    else:\n","        # Create a new Excel file and save the DataFrame\n","        with pd.ExcelWriter(path, engine='openpyxl') as writer:\n","            # Save the DataFrame to the specified sheet\n","            results_df.to_excel(writer, sheet_name=sheet_name, index=True)"],"metadata":{"id":"jm8iOYjm0lS7","executionInfo":{"status":"ok","timestamp":1724543718611,"user_tz":300,"elapsed":3,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["def plot_learning_curve(estimator, X, y, model_name,path):\n","    \"\"\"\n","    Plot the learning curve for a given estimator.\n","\n","    Parameters:\n","    - estimator: The machine learning model or estimator to evaluate.\n","    - X (pd.DataFrame or np.ndarray): Feature matrix.\n","    - y (pd.Series or np.ndarray): Target variable.\n","    - model_name (str): Name of the model to include in the plot title.\n","    \"\"\"\n","    # Calculate learning curve data\n","    train_sizes, train_scores, test_scores = learning_curve(\n","        estimator, X, y, cv=5, n_jobs=-1,\n","        train_sizes=np.linspace(0.1, 1.0, 10))\n","\n","    # Create a new figure\n","    plt.figure()\n","\n","    # Plot training scores\n","    plt.plot(train_sizes, np.mean(train_scores, axis=1), 'o-', color='r', label='Training score')\n","\n","    # Plot cross-validation scores\n","    plt.plot(train_sizes, np.mean(test_scores, axis=1), 'o-', color='g', label='Cross-validation score')\n","\n","    # Set x-axis label\n","    plt.xlabel('Training examples')\n","\n","    # Set y-axis label\n","    plt.ylabel('Score')\n","\n","    # Set plot title\n","    plt.title(f'Learning Curve for {model_name}')\n","\n","    # Add legend\n","    plt.legend(loc='best')\n","\n","    # Add grid for better readability\n","    plt.grid()\n","\n","    # Ensure the directory for saving the file exists.\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","\n","    try:\n","        # Save the plot to the specified path with a name based on the title, scenario name, and model name.\n","        plt.savefig(f\"{path}/Learning Curve_{model_name}.png\")\n","    except Exception as e:\n","        # Print an error message if there is a problem saving the file.\n","        print(f\"Error saving the learning Curve plot: {e}\")\n","    finally:\n","        # Close the plot to free up memory.\n","        plt.close()"],"metadata":{"id":"B_QLRscbq9i7","executionInfo":{"status":"ok","timestamp":1724543718611,"user_tz":300,"elapsed":3,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["def param(model, model_name, X, y):\n","    \"\"\"\n","    Perform hyperparameter tuning using RandomizedSearchCV and plot learning curves.\n","\n","    Parameters:\n","    - model: The machine learning model to tune.\n","    - model_name (str): The name of the model to configure hyperparameters for.\n","    - X (pd.DataFrame or np.ndarray): Feature matrix.\n","    - y (pd.Series or np.ndarray): Target variable.\n","\n","    Returns:\n","    - best_model: The best model found by RandomizedSearchCV.\n","    \"\"\"\n","\n","    # Dictionary to hold the parameter grid for each model\n","    param_dist = {}\n","\n","    # Define parameter grids for different models\n","    if model_name == 'LDA':\n","        param_dist = {\n","            'solver': ['svd', 'lsqr', 'eigen'],\n","            'shrinkage': [None, 'auto', 0.1, 0.5, 1.0],\n","            'n_components': [None, 1, 2, 3],\n","            'store_covariance': [True, False]\n","        }\n","\n","    elif model_name == 'LogisticRegression':\n","        param_dist = {\n","            'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n","            'C': [0.01, 0.1, 1, 10, 100],\n","            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n","            'max_iter': [100, 200, 500],\n","            'l1_ratio': [None, 0.1, 0.5, 0.7, 1.0]\n","        }\n","\n","    elif model_name == 'RandomForest':\n","        param_dist = {\n","            'n_estimators': [50, 100, 200],\n","            'max_features': ['sqrt', 'log2'],\n","            'max_depth': [None, 10, 20, 30, 40],\n","            'min_samples_split': [2, 5, 10],\n","            'min_samples_leaf': [1, 2, 4],\n","            'bootstrap': [True, False]\n","        }\n","\n","    elif model_name == 'KNN':\n","        param_dist = {\n","            'n_neighbors': [3, 5, 7, 9, 11],\n","            'weights': ['uniform', 'distance'],\n","            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n","            'leaf_size': [10, 20, 30, 40],\n","            'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n","        }\n","\n","    elif model_name == 'SVC':\n","        param_dist = {\n","            'C': [0.01, 0.1, 1, 10, 100],\n","            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n","            'degree': [2, 3, 4],  # Relevant only for 'poly' kernel\n","            'gamma': ['scale', 'auto'],\n","            'coef0': [0.0, 0.1, 0.5, 1.0],  # Relevant only for 'poly' and 'sigmoid' kernels\n","            'class_weight': [None, 'balanced']\n","        }\n","\n","    elif model_name == 'LinearRegression':\n","        param_dist = {\n","            'fit_intercept': [True, False],\n","            'positive': [True, False],\n","            'copy_X': [True, False]\n","        }\n","\n","    elif model_name == 'RandomForestRegressor':\n","        param_dist = {\n","            'n_estimators': [50, 100, 200],\n","            'max_features': ['sqrt', 'log2', None],\n","            'max_depth': [None, 10, 20, 30, 40],\n","            'min_samples_split': [2, 5, 10],\n","            'min_samples_leaf': [1, 2, 4],\n","            'bootstrap': [True, False]\n","        }\n","\n","    elif model_name == 'SVR':\n","        param_dist = {\n","            'C': [0.01, 0.1, 1, 10, 100],\n","            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n","            'degree': [2, 3, 4],  # Relevant only for 'poly' kernel\n","            'gamma': ['scale', 'auto'],\n","            'coef0': [0.0, 0.1, 0.5, 1.0],  # Relevant only for 'poly' and 'sigmoid' kernels\n","            'epsilon': [0.01, 0.1, 1]\n","        }\n","\n","    # Perform hyperparameter tuning using RandomizedSearchCV\n","    best_model = RandomizedSearchCV(\n","        estimator=model,\n","        param_distributions=param_dist,\n","        n_iter=10,\n","        cv=3,\n","        verbose=2,\n","        random_state=42,\n","        n_jobs=-1\n","    )\n","    best_model.fit(X, y)\n","\n","    # Plot learning curve for the best model\n","    plot_learning_curve(best_model.best_estimator_, X, y, model_name,'/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img')\n","\n","    # Save all search results to Excel\n","    results = pd.DataFrame(best_model.cv_results_)\n","    save_excel(results, '/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/model_results.xlsx', model_name)\n","\n","    # Save the top 3 results to a separate Excel file\n","    top_results = results.nlargest(3, 'mean_test_score')\n","    save_excel(top_results, '/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/model_best_results.xlsx', model_name)\n","\n","    return best_model"],"metadata":{"id":"Z-lj_CLN8oYA","executionInfo":{"status":"ok","timestamp":1724543718896,"user_tz":300,"elapsed":5,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["import os  # Import the os module to interact with the operating system.\n","import numpy as np  # Import numpy for mathematical operations and array manipulations.\n","import matplotlib.pyplot as plt  # Import matplotlib for creating plots and visualizations.\n","\n","def plot_confusion_matrix(path, scenario_name, model_name, cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.BuGn):\n","    \"\"\"\n","    Plots the confusion matrix with options for normalization and saves the plot.\n","\n","    Parameters:\n","    - path: Directory path to save the plot.\n","    - scenario_name: Name of the scenario for the plot title.\n","    - model_name: Name of the model for the plot title.\n","    - cm: Confusion matrix to plot.\n","    - classes: List of class names.\n","    - normalize: Whether to normalize the confusion matrix.\n","    - title: Title for the plot.\n","    - cmap: Color map for the plot.\n","    \"\"\"\n","\n","    if normalize:\n","        # Normalize the confusion matrix by dividing each value by the sum of its row.\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(f\"Confusion Matrix normalized for {scenario_name}\")  # Print a message indicating that the matrix is normalized.\n","    else:\n","        print(f'Confusion Matrix for {scenario_name}')  # Print a message indicating that the matrix is not normalized.\n","\n","    print(cm)  # Print the confusion matrix to the console.\n","\n","    # Create a new figure for the plot.\n","    plt.figure(figsize=(10, 10))\n","    # Display the confusion matrix as an image with a color map.\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    # Set the title of the plot, including the model name and scenario name.\n","    plt.title(f'{title} for {model_name} in {scenario_name}')\n","    # Add a color bar next to the plot to show the color map scale.\n","    plt.colorbar()\n","\n","    # Create a list of tick marks on the x-axis, based on the number of classes.\n","    tick_marks = np.arange(len(classes))\n","    # Set the x-axis tick labels to the class names and rotate them 45 degrees.\n","    plt.xticks(tick_marks, classes, rotation=45, fontsize=16)\n","    # Set the y-axis tick labels to the class names.\n","    plt.yticks(tick_marks, classes, fontsize=16)\n","\n","    # Define the format for displaying the values in the matrix.\n","    fmt = '.2f' if normalize else 'd'\n","    # Define the threshold for text color based on the maximum value in the matrix.\n","    thresh = cm.max() / 2.\n","    # Iterate over each cell in the confusion matrix.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            # Place the cell value in the plot with the specified format.\n","            plt.text(j, i, format(cm[i, j], fmt),\n","                     ha=\"center\", va=\"center\",\n","                     fontsize=16,  # Font size set to 16.\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")  # Text color is white if the value is greater than the threshold, otherwise black.\n","\n","    # Adjust the layout of the subplots to prevent overlap.\n","    plt.tight_layout()\n","    # Set the y-axis label and font size.\n","    plt.ylabel('True label', fontsize=16)\n","    # Set the x-axis label and font size.\n","    plt.xlabel('Predicted label', fontsize=16)\n","\n","    # Ensure the directory for saving the file exists.\n","    os.makedirs(os.path.dirname(path), exist_ok=True)\n","\n","    try:\n","        # Save the plot to the specified path with a name based on the title, scenario name, and model name.\n","        plt.savefig(f\"{path}/{title}_{scenario_name}_{model_name}.png\")\n","    except Exception as e:\n","        # Print an error message if there is a problem saving the file.\n","        print(f\"Error saving the confusion matrix plot: {e}\")\n","    finally:\n","        # Close the plot to free up memory.\n","        plt.close()"],"metadata":{"id":"e_DB4JiHr6KK","executionInfo":{"status":"ok","timestamp":1724543718896,"user_tz":300,"elapsed":5,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt  # Import matplotlib for creating plots.\n","\n","def evaluate_regression_model(path, y_true, y_pred, scenario_name, model_name, title='Evaluate Regression'):\n","    \"\"\"\n","    Evaluate a regression model by plotting predicted vs. actual values and residuals.\n","\n","    Parameters:\n","    - path: Directory path to save the plots.\n","    - y_true: Array-like of true target values.\n","    - y_pred: Array-like of predicted values.\n","    - scenario_name: Name of the scenario for the plot title.\n","    - model_name: Name of the model for the plot title.\n","    - title: Title for the plots.\n","    \"\"\"\n","\n","    # Create a new figure with specified size.\n","    plt.figure(figsize=(12, 6))\n","\n","    # Plot of Predictions vs True Values\n","    plt.tight_layout()  # Adjust the layout to prevent overlap.\n","    plt.scatter(y_true, y_pred, alpha=0.5)  # Scatter plot of true values vs. predicted values.\n","    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--', lw=2)  # Add a red dashed line for perfect predictions.\n","    plt.xlabel('True Values')  # Label for the x-axis.\n","    plt.ylabel('Predictions')  # Label for the y-axis.\n","    plt.title(f'{title} (Predictions vs True Values) for {model_name} in {scenario_name}', fontsize=8)  # Title for the plot.\n","    print(f\"{path}/{title}_{scenario_name}_{model_name}_predictions.png\")  # Print the path where the plot will be saved.\n","    plt.savefig(f\"{path}/{title}_{scenario_name}_{model_name}_predictions.png\")  # Save the plot to the specified path.\n","    plt.close()  # Close the plot to free up memory.\n","\n","    # Plot of Residuals\n","    residuals = y_true - y_pred  # Calculate residuals (true values - predicted values).\n","    plt.figure(figsize=(12, 6))  # Create a new figure with specified size.\n","    plt.tight_layout()  # Adjust the layout to prevent overlap.\n","    plt.scatter(y_pred, residuals, alpha=0.5)  # Scatter plot of predicted values vs. residuals.\n","    plt.axhline(y=0, color='r', linestyle='--')  # Add a red dashed line at y=0 to show the zero residual line.\n","    plt.xlabel('Predictions')  # Label for the x-axis.\n","    plt.ylabel('Residuals')  # Label for the y-axis.\n","    plt.title(f'{title} (Residuals Plot) for {model_name} in {scenario_name}', fontsize=8)  # Title for the plot.\n","    print(f\"{path}/{title}_{scenario_name}_{model_name}_residuals.png\")  # Print the path where the plot will be saved.\n","    plt.savefig(f\"{path}/{title}_{scenario_name}_{model_name}_residuals.png\")  # Save the plot to the specified path.\n","    plt.close()  # Close the plot to free up memory."],"metadata":{"id":"bz765GlFzIiK","executionInfo":{"status":"ok","timestamp":1724543718896,"user_tz":300,"elapsed":4,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["import pandas as pd  # Import pandas for data manipulation and saving results.\n","from sklearn.model_selection import train_test_split, cross_val_score  # Import train_test_split for splitting data and cross_val_score for cross-validation.\n","from sklearn.preprocessing import StandardScaler  # Import StandardScaler for feature scaling.\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score  # Import various metrics for model evaluation.\n","import matplotlib.pyplot as plt  # Import matplotlib for plotting confusion matrices.\n","\n","def model_class(X, y, models, path, scenario_name):\n","    \"\"\"\n","    Evaluates different classification models by performing feature selection, training, cross-validation, and evaluation.\n","\n","    Parameters:\n","    - X: Feature matrix.\n","    - y: Target vector.\n","    - models: Dictionary of model names and instances.\n","    - path: Directory path to save the results and plots.\n","    - scenario_name: Name of the scenario for the plot title and file names.\n","    \"\"\"\n","\n","    X, y = select_features(X, y)  # Perform feature selection on the data.\n","\n","    # Create a dictionary to store DataFrames for different scenarios.\n","    results_dict_class = {}\n","\n","    # Split the data into training and testing sets.\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","    # Standardize the features by scaling.\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)  # Fit and transform the training data.\n","    X_test = scaler.transform(X_test)  # Transform the test data using the same scaler.\n","\n","    results = []  # Initialize an empty list to store results for each model.\n","\n","    for model_name, model in models.items():\n","        model = param(model, model_name, X, y)  # Adjust model parameters using hyperparameter tuning.\n","\n","        # Train the model with the training data.\n","        model.fit(X_train, y_train)\n","\n","        # Perform cross-validation on the training data with the best model found.\n","        cross_val_scores = cross_val_score(\n","            estimator=model.best_estimator_,  # Use the best model from hyperparameter tuning.\n","            X=X_train,\n","            y=y_train,\n","            cv=10,  # 10-fold cross-validation.\n","            n_jobs=-1  # Use all available processors.\n","        )\n","        print(f'Cross-validation scores for {model_name}: {cross_val_scores}')\n","\n","        # Make predictions on the test set.\n","        y_pred = model.predict(X_test)\n","\n","        # Calculate evaluation metrics for the model.\n","        accuracy = accuracy_score(y_test, y_pred) * 100\n","        precision = precision_score(y_test, y_pred, average='weighted') * 100\n","        recall = recall_score(y_test, y_pred, average='weighted') * 100\n","        conf_matrix = confusion_matrix(y_test, y_pred)\n","        tn = conf_matrix[0, 0]  # True negatives.\n","        fp = conf_matrix[0, 1]  # False positives.\n","        specificity = tn / (tn + fp) * 100  # Calculate specificity.\n","        f1 = f1_score(y_test, y_pred, average='weighted') * 100  # Calculate F1 score.\n","        auc = roc_auc_score(y_test, y_pred)  # Calculate the AUC score.\n","\n","        # Append the results to the list.\n","        results.append({\n","            'Model': model_name,\n","            'Accuracy (%)': accuracy,\n","            'Sensitivity (%)': recall,\n","            'Specificity (%)': specificity,\n","            'Precision (%)': precision,\n","            'F1 Score (%)': f1,\n","            'AUC': auc\n","        })\n","\n","        # Define class names for confusion matrix.\n","        class_names = ['HC', 'PDMCI']\n","\n","        # Plot and save the confusion matrix.\n","        plot_confusion_matrix(path, scenario_name, model_name, conf_matrix, normalize=False, classes=class_names, title='Confusion matrix')\n","\n","    # Convert the list of results into a DataFrame.\n","    results_df = pd.DataFrame(results)\n","    results_df.set_index('Model', inplace=True)  # Set the model name as the index.\n","\n","    # Save the results to an Excel file.\n","    save_excel(results_df, path + '/model_comparison_results_class.xlsx', scenario_name)"],"metadata":{"id":"1SyATG5P0o17","executionInfo":{"status":"ok","timestamp":1724543718896,"user_tz":300,"elapsed":4,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["import numpy as np  # Import numpy for numerical operations.\n","import pandas as pd  # Import pandas for data manipulation and saving results.\n","from sklearn.model_selection import train_test_split, cross_val_score  # Import train_test_split for splitting data and cross_val_score for cross-validation.\n","from sklearn.preprocessing import StandardScaler  # Import StandardScaler for feature scaling.\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, roc_auc_score  # Import regression metrics for evaluation.\n","import matplotlib.pyplot as plt  # Import matplotlib for plotting regression results.\n","\n","def model_reg(X, y, models, path, scenario_name):\n","    \"\"\"\n","    Evaluates different regression models by performing feature selection, training, cross-validation, and evaluation.\n","\n","    Parameters:\n","    - X: Feature matrix.\n","    - y: Target vector.\n","    - models: Dictionary of model names and instances.\n","    - path: Directory path to save the results and plots.\n","    - scenario_name: Name of the scenario for the plot title and file names.\n","    \"\"\"\n","\n","    X, y = select_features(X, y)  # Perform feature selection on the data.\n","\n","    # Create a dictionary to store DataFrames for different scenarios.\n","    results_dict_reg = {}\n","\n","    # Split the data into training and testing sets.\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","    # Standardize the features by scaling.\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)  # Fit and transform the training data.\n","    X_test = scaler.transform(X_test)  # Transform the test data using the same scaler.\n","\n","    results = []  # Initialize an empty list to store results for each model.\n","\n","    for model_name, model in models.items():\n","        model = param(model, model_name, X, y)  # Adjust model parameters using hyperparameter tuning.\n","\n","        # Train the model with the training data.\n","        model.fit(X_train, y_train)\n","\n","        # Perform cross-validation on the training data with the best model found.\n","        cross_val_scores = cross_val_score(\n","            estimator=model.best_estimator_,  # Use the best model from hyperparameter tuning.\n","            X=X_train,\n","            y=y_train,\n","            cv=10,  # 10-fold cross-validation.\n","            n_jobs=-1  # Use all available processors.\n","        )\n","        print(f'Cross-validation scores for {model_name}: {cross_val_scores}')\n","\n","        # Predict the test set outcomes.\n","        y_pred = model.predict(X_test)\n","\n","        # Calculate evaluation metrics for regression models.\n","        mse = np.sqrt(mean_squared_error(y_test, y_pred))  # Calculate the Root Mean Squared Error (RMSE).\n","        mae = mean_absolute_error(y_test, y_pred)  # Calculate the Mean Absolute Error (MAE).\n","        r2 = r2_score(y_test, y_pred)  # Calculate the R-squared score.\n","\n","        # Append the results to the list.\n","        results.append({\n","            'Model': model_name,\n","            'MSE': mse,\n","            'MAE': mae,\n","            'R2 Score': r2\n","        })\n","\n","        # Plot and save the evaluation results for regression models.\n","        evaluate_regression_model(path, y_test, y_pred, scenario_name, model_name, title='Evaluate Regression')\n","\n","    # Convert the list of results into a DataFrame.\n","    results_df = pd.DataFrame(results)\n","    results_df.set_index('Model', inplace=True)  # Set the model name as the index.\n","\n","    # Save the results to an Excel file.\n","    save_excel(results_df, path + '/model_comparison_results_reg.xlsx', scenario_name)"],"metadata":{"id":"1CKdmqVa5Aph","executionInfo":{"status":"ok","timestamp":1724543718896,"user_tz":300,"elapsed":4,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}}},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":["# Classification model"],"metadata":{"id":"lcu_sc8EKx9J"}},{"cell_type":"code","source":["# Define the path where results will be saved\n","path = r'/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img'\n","\n","# Create a dictionary of classification models to be evaluated\n","models = {\n","    'LDA_Classifier': LinearDiscriminantAnalysis(),  # Linear Discriminant Analysis model\n","    'LogisticRegressionClassifier': LogisticRegression(max_iter=1000, random_state=42),  # Logistic Regression model with increased max iterations\n","    'RandomForestClassifier': RandomForestClassifier(random_state=42),  # Random Forest Classifier with fixed random state\n","    'KNN_Classifier': KNeighborsClassifier(n_neighbors=3),  # k-Nearest Neighbors model with 3 neighbors\n","    'SVClassifier': SVC(random_state=42)  # Support Vector Classifier with fixed random state\n","}\n","\n","# Define classification scenarios with corresponding feature matrices and target vectors\n","scenarios_class = {\n","    'Group vs EEG': (X_class_EEG, y_class),  # Scenario for EEG-based classification\n","    'Group vs MRI': (X_class_MRI, y_class),  # Scenario for MRI-based classification\n","    # 'Group vs EEG and MRI': (X_class_EEG_MRI, y_class)  # Scenario for combined EEG and MRI (commented out)\n","}\n","\n","# Iterate over each scenario\n","for scenario_name, (X, y) in scenarios_class.items():\n","    # Evaluate each model for the current scenario\n","    model_class(X, y, models, path, scenario_name)\n","\n","# Print a message indicating that the results have been saved\n","print(\"Classification results saved to Excel with separate sheets for each scenario.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuju1tvy0sfj","executionInfo":{"status":"ok","timestamp":1724543778970,"user_tz":300,"elapsed":60078,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}},"outputId":"a5b8dd1d-e963-4a11-aff5-5cc8b7f24130"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n"]},{"output_type":"stream","name":"stdout","text":["Selected features: ['Age', 'Sex', 'Education', 'De_F', 'De_C', 'De_P', 'De_O', 'De_T', 'De_L', 'Th_F', 'Th_C', 'Th_P', 'Th_O', 'Th_T', 'Th_L', 'A1_F', 'A1_C', 'A1_P', 'A1_O', 'A1_T', 'A1_L', 'A2_F', 'A2_C', 'A2_P', 'A2_O', 'A2_T', 'A2_L', 'A3_F', 'A3_C', 'A3_P', 'A3_O', 'A3_T', 'A3_L', 'B1_F', 'B1_C', 'B1_P', 'B1_O', 'B1_T', 'B1_L', 'B2_F', 'B2_C', 'B2_P', 'B2_O', 'B2_T', 'B2_L', 'Ga_F', 'Ga_C', 'Ga_P', 'Ga_O', 'Ga_T', 'Ga_L', 'De_global', 'Th_global', 'A1_global', 'A3_global']\n","Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for LDA_Classifier: [0.625      0.875      0.57142857 0.57142857 0.85714286 0.57142857\n"," 0.71428571 0.85714286 0.85714286 0.42857143]\n","Confusion Matrix for Group vs EEG\n","[[13  6]\n"," [ 1 12]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for LogisticRegressionClassifier: [0.625      0.875      0.85714286 0.85714286 1.         0.71428571\n"," 0.85714286 0.85714286 1.         0.71428571]\n","Confusion Matrix for Group vs EEG\n","[[17  2]\n"," [ 2 11]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for RandomForestClassifier: [0.75       1.         0.57142857 0.71428571 1.         0.57142857\n"," 0.71428571 0.42857143 1.         0.57142857]\n","Confusion Matrix for Group vs EEG\n","[[17  2]\n"," [ 2 11]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for KNN_Classifier: [0.75       0.875      0.71428571 0.85714286 1.         0.71428571\n"," 0.85714286 0.85714286 1.         0.42857143]\n","Confusion Matrix for Group vs EEG\n","[[16  3]\n"," [ 2 11]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for SVClassifier: [0.75       0.875      0.85714286 0.85714286 0.85714286 0.85714286\n"," 0.71428571 0.71428571 1.         0.57142857]\n","Confusion Matrix for Group vs EEG\n","[[17  2]\n"," [ 2 11]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n"]},{"output_type":"stream","name":"stdout","text":["Selected features: ['Age', 'Sex', 'Education', 'Visual_Network_Normalized', 'SomatoMotor_Network_Normalized', 'DAN_Normalized', 'VAN_Normalized', 'Limbic_Network_Normalized', 'FrontoParietal_Network_Normalized', 'DMN_Normalized']\n","Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for LDA_Classifier: [0.33333333 0.83333333 1.         0.6        1.         0.6\n"," 0.6        1.         0.8        0.6       ]\n","Confusion Matrix for Group vs MRI\n","[[ 3  4]\n"," [ 3 13]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for LogisticRegressionClassifier: [0.33333333 0.83333333 0.8        0.6        1.         0.6\n"," 0.8        1.         0.8        0.8       ]\n","Confusion Matrix for Group vs MRI\n","[[ 3  4]\n"," [ 3 13]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for RandomForestClassifier: [0.33333333 0.33333333 1.         0.8        0.8        0.6\n"," 0.8        1.         0.8        0.6       ]\n","Confusion Matrix for Group vs MRI\n","[[4 3]\n"," [7 9]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for KNN_Classifier: [0.5        0.66666667 0.8        0.6        0.6        0.6\n"," 1.         0.8        0.8        0.6       ]\n","Confusion Matrix for Group vs MRI\n","[[ 6  1]\n"," [ 4 12]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for SVClassifier: [0.5        0.83333333 1.         0.8        0.8        0.6\n"," 0.8        0.8        0.8        0.6       ]\n","Confusion Matrix for Group vs MRI\n","[[ 4  3]\n"," [ 4 12]]\n","Classification results saved to Excel with separate sheets for each scenario.\n"]}]},{"cell_type":"markdown","source":["# Regression model"],"metadata":{"id":"BrfxUy7tKlXf"}},{"cell_type":"code","source":["# Define the regression models to be evaluated.\n","models = {\n","    'LinearRegression': LinearRegression(),  # Instantiate a Linear Regression model.\n","    'RandomForestRegressor': RandomForestRegressor(random_state=42),  # Instantiate a Random Forest Regressor model with a fixed random state for reproducibility.\n","    'SVRegressor': SVR()  # Instantiate a Support Vector Regressor model.\n","}\n","\n","# Define the regression scenarios, where each scenario maps to feature matrix X and target vector y.\n","scenarios_reg = {\n","    'EEG vs MMSE': (X_reg_EEG, y_reg),  # Scenario where EEG features are used to predict MMSE scores.\n","    'MRI vs MMSE': (X_reg_MRI, y_reg),  # Scenario where MRI features are used to predict MMSE scores.\n","    'TELE vs MMSE': (X_reg_TELE, y_reg),  # Scenario where TELE features are used to predict MMSE scores.\n","    # Uncomment these lines if additional scenarios need to be evaluated:\n","    # 'EEG vs TELE': (X_reg_EEG, y_reg_2),  # Scenario where EEG features are used to predict TELE scores.\n","    # 'MRI vs TELE': (X_reg_MRI, y_reg_2),  # Scenario where MRI features are used to predict TELE scores.\n","    # 'EEG and TELE vs MMSE': (X_reg_TELE_EEG, y_reg),  # Scenario where both EEG and TELE features are used to predict MMSE scores.\n","    # 'MRI and TELE vs MMSE': (X_reg_TELE_MRI, y_reg)  # Scenario where both MRI and TELE features are used to predict MMSE scores.\n","}\n","\n","# Iterate over each scenario defined in the scenarios_reg dictionary.\n","for scenario_name, (X, y) in scenarios_reg.items():\n","    # Call the model_reg function for each scenario, passing the features, target, models, path to save results, and scenario name.\n","    model_reg(X, y, models, path, scenario_name)\n","\n","# Print a message indicating that regression results have been saved to an Excel file, with each scenario on a separate sheet.\n","print(\"Regression results saved to Excel with separate sheets for each scenario.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgnQRKTe5HXV","executionInfo":{"status":"ok","timestamp":1724543887299,"user_tz":300,"elapsed":108344,"user":{"displayName":"Verónica Henao Isaza","userId":"14605473930429324059"}},"outputId":"ded402f6-d2f0-47f2-8d80-daa164586238"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n"]},{"output_type":"stream","name":"stdout","text":["Selected features: ['Age', 'Sex', 'Education', 'De_F', 'De_C', 'De_P', 'De_O', 'De_T', 'De_L', 'Th_F', 'Th_C', 'Th_P', 'Th_O', 'Th_T', 'Th_L', 'A1_F', 'A1_C', 'A1_P', 'A1_O', 'A1_T', 'A1_L', 'A2_F', 'A2_C', 'A2_P', 'A2_O', 'A2_T', 'A2_L', 'A3_F', 'A3_C', 'A3_P', 'A3_O', 'A3_T', 'A3_L', 'B1_F', 'B1_C', 'B1_P', 'B1_O', 'B1_T', 'B1_L', 'B2_F', 'B2_C', 'B2_P', 'B2_O', 'B2_T', 'B2_L', 'Ga_F', 'Ga_C', 'Ga_P', 'Ga_O', 'Ga_T', 'Ga_L', 'De_global', 'Th_global', 'A1_global', 'A3_global']\n","Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 8 candidates, totalling 24 fits\n","Cross-validation scores for LinearRegression: [  0.50208091   0.27589688  -0.36401029 -17.96431986   0.46995858\n","   0.21293425   0.31850291   0.24944532  -0.10986563  -1.0915697 ]\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_EEG vs MMSE_LinearRegression_predictions.png\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_EEG vs MMSE_LinearRegression_residuals.png\n","Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","Cross-validation scores for RandomForestRegressor: [ 0.16511626  0.28392619  0.26928582 -8.59865919  0.25614147  0.2287018\n","  0.5243258  -0.01360112  0.18761215  0.09630215]\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_EEG vs MMSE_RandomForestRegressor_predictions.png\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_EEG vs MMSE_RandomForestRegressor_residuals.png\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for SVRegressor: [-8.80964109e-02  3.68310140e-02  3.21023144e-01 -5.55144363e+00\n"," -6.59178530e-02  5.57473924e-02 -3.28047022e-03  2.67229728e-01\n"," -5.01267737e-03 -4.36988452e-02]\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_EEG vs MMSE_SVRegressor_predictions.png\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_EEG vs MMSE_SVRegressor_residuals.png\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n"]},{"output_type":"stream","name":"stdout","text":["Selected features: ['Age', 'Sex', 'Education', 'Visual_Network_Normalized', 'SomatoMotor_Network_Normalized', 'DAN_Normalized', 'VAN_Normalized', 'Limbic_Network_Normalized', 'FrontoParietal_Network_Normalized', 'DMN_Normalized']\n","Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 8 candidates, totalling 24 fits\n","Cross-validation scores for LinearRegression: [-2.34587648  0.81015956  0.52825593 -1.66248017  0.46576267  0.5554648\n"," -1.98382087  0.4275992   0.83904006 -8.30788968]\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_MRI vs MMSE_LinearRegression_predictions.png\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_MRI vs MMSE_LinearRegression_residuals.png\n","Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","Cross-validation scores for RandomForestRegressor: [-1.42525981  0.68723048  0.55490198 -5.20045566  0.71866884  0.45116386\n"," -0.72939441  0.29383631  0.56488845 -0.36285165]\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_MRI vs MMSE_RandomForestRegressor_predictions.png\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_MRI vs MMSE_RandomForestRegressor_residuals.png\n","Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for SVRegressor: [-1.37522647  0.55356795  0.4517734  -2.54503844  0.59053983  0.6027281\n"," -0.50821653  0.46517399  0.32124333 -1.12216733]\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_MRI vs MMSE_SVRegressor_predictions.png\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_MRI vs MMSE_SVRegressor_residuals.png\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n","/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 3, but rank is 1\n","  warnings.warn('covariance of constraints does not have full '\n"]},{"output_type":"stream","name":"stdout","text":["Selected features: ['Age', 'Sex', 'Education', 'TASK1', 'TASK2', 'TASK3', 'TASK4', 'TASK5', 'TASK6', 'TASK7']\n","Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 8 candidates, totalling 24 fits\n","Cross-validation scores for LinearRegression: [ -0.46535595  -0.7860557  -14.70580413  -0.80870876   0.39329179\n","   0.8763016   -0.36674957  -0.74086955  -0.11414626   0.12229674]\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_TELE vs MMSE_LinearRegression_predictions.png\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_TELE vs MMSE_LinearRegression_residuals.png\n","Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","Fitting 3 folds for each of 10 candidates, totalling 30 fits\n","Cross-validation scores for RandomForestRegressor: [ 0.62468574  0.42599709 -4.03217234 -0.77551711  0.20883849  0.86302452\n"," -0.14932059  0.11250336 -0.02187071  0.5494715 ]\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_TELE vs MMSE_RandomForestRegressor_predictions.png\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_TELE vs MMSE_RandomForestRegressor_residuals.png\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n","Cross-validation scores for SVRegressor: [-0.39166438  0.03600652 -0.87824172 -2.04634128 -0.12045355  0.50965559\n"," -0.47632467 -0.41882795  0.16458177  0.94736587]\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_TELE vs MMSE_SVRegressor_predictions.png\n","/content/drive/MyDrive/Sapienza/Workshops/Workshop 4/Img/Evaluate Regression_TELE vs MMSE_SVRegressor_residuals.png\n","Regression results saved to Excel with separate sheets for each scenario.\n"]}]}]}